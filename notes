# Tensor Flow compiled using AVX instructions. If there is an error message to this effect, implement the following
a) pip install intel-tensorflow
b) pip install tensorflow tensorflow-cpu
c) It is possible that there will be error messages as a result of compatability between updates and editions,
which pip does not take into account.

# pixelation is a GPU requirement, devised by NVIDIA, and multiple cores are now placed on a chip
a) hundreds or thousands of parallel cores and threads run on the chip for AI/ML workloads
b) cycles of batches run simultaneously and optimise performance (the 'single clock cycle')
c) TPU is a tensor processing unit, specialised parallel processors built for AI/ML
d) V-RAM holds the model weights simultaneously, TPU take coding functions like RELU with silicone acceleration
with certain mathematical functions in AI, computations created run even faster

# weights are multiplied by the values of the function and applied to every single neuron: enter GPU
# cuda is by NVIDIA and runs from the device GPU into the NN and the core - which core is assigned to compute?
This is the function of cuda. 


> python iris_demo.py 2>nul
5.0 3.5 1.3 0.3 setosa
5.5 2.6 4.4 1.2 versicolor
6.7 3.1 5.6 2.4 virginica

> pip install https://cntk.ai.PythonWheel/CPU-Only/cntk-2.0rc1-cp35-cp35m-win_amd64.whl
> python -c "import cntk; print(cntk.__version__)"
hidden[0] = tanh( (6.9)(0.6100) +
                  (3.1)(0.7152) +
                  (4.6)(-1.0855) +
                  (1.3)(-1.0687) + 0.1468 )
          = tanh(0.1903)
          = 0.1882

# compute sun of products + bias
pre-output[0] = (0.1882)(3.2200) + (0.9999)(-0.8545) + 0.1859
              = -0.0625
pre-output[1] = (0.1882)(-0.7311) + (0.9999)(0.3553) + 0.6735
              = 0.8912
pre-output[2] = (0.1882)(-4.1944) + (0.9999)(0.0244) + (-0.8595)
              = -1.6246

# applied softmax values so they sum to 1.0 and can be interpreted as probabilities.
output[0] = exp(-0.0625) / exp(-0.0625) + exp(0.8912) + exp(-1.6246)
          = 0.263
output[1] = exp(0.8912) / exp(-0.0625) + exp(0.8912) + exp(-1.6246)
          = 0.682
output[2] = exp(-1.6246) / exp(-0.0625) + exp(0.8912) + exp(-1.6246)
          = 0.055

# iris_demo.py
import cntk as C
...
def my_print(arr, dec):
def create_reader(path, is_training, input_dim,
  output_dim):
def save_weights(fn, ihWeights, hBiases,
  hoWeights, oBiases):
def do_demo():
def main():
  print("\nBegin Iris demo (CNTK 2.0) \n")
  np.random.seed(0)
  do_demo()  # all the work is done in do_demo()
if __name__ == "__main__":
  main()

# complete demo prgrame with a helper function
# iris_demo.py
# Anaconda 4.1.1 (Python 3.5, NumPy 1.11.1)
# CNTK 2.0 RC1
# Use a one-hidden layer simple NN with 2 hidden nodes
# to classify the Iris Dataset.
# This version uses the built-in Reader functions and
# data files that use the CTF format.
# trainData_cntk.txt - 120 items (40 each class)
# testData_cntk.txt - remaining 30 items
import numpy as np
import cntk as C
from cntk import Trainer  # to train the NN
from cntk.learners import sgd, learning_rate_schedule, \
  UnitType
from cntk.ops import *  # input_variable() def
from cntk.logging import ProgressPrinter
from cntk.initializer import glorot_uniform
from cntk.layers import default_options, Dense
from cntk.io import CTFDeserializer, MinibatchSource, \
  StreamDef, StreamDefs, INFINITELY_REPEAT
# =====
def my_print(arr, dec):
  # print an array of float/double with dec decimals
  fmt = "%." + str(dec) + "f" # like %.4f
  for i in range(0, len(arr)):
    print(fmt % arr[i] + '  ', end='')
  print("\n")
def create_reader(path, is_training, input_dim, output_dim):
  return MinibatchSource(CTFDeserializer(path, StreamDefs(
    features = StreamDef(field='attribs', shape=input_dim,
      is_sparse=False),
    labels = StreamDef(field='species', shape=output_dim,
      is_sparse=False)
  )), randomize = is_training,
    max_sweeps = INFINITELY_REPEAT if is_training else 1)
def save_weights(fn, ihWeights, hBiases,
  hoWeights, oBiases):
  f = open(fn, 'w')
  for vals in ihWeights:
    for v in vals:
      f.write("%s\n" % v)
  for v in hBiases:
    f.write("%s\n" % v)
  for vals in hoWeights:
    for v in vals:
      f.write("%s\n" % v)
  for v in oBiases:
    f.write("%s\n" % v)
  f.close()
def do_demo():
  # create NN, train, test, predict
  input_dim = 4
  hidden_dim = 2
  output_dim = 3
  train_file = "trainData_cntk.txt"
  test_file = "testData_cntk.txt"
  input_Var = C.ops.input(input_dim, np.float32)
  label_Var = C.ops.input(output_dim, np.float32)
  print("Creating a 4-2-3 tanh softmax NN for Iris data ") # create the NN
  with default_options(init = glorot_uniform()):
    hLayer = Dense(hidden_dim, activation=C.ops.tanh,
      name='hidLayer')(input_Var) 
    oLayer = Dense(output_dim, activation=C.ops.softmax,
      name='outLayer')(hLayer)
  nnet = oLayer
  # ---------------------------------- hte special CTF format and then use built-in CNTK reader functions
  print("Creating a cross entropy mini-batch Trainer \n")
  ce = C.cross_entropy_with_softmax(nnet, label_Var)
  pe = C.classification_error(nnet, label_Var)
  fixed_lr = 0.05
  lr_per_batch = learning_rate_schedule(fixed_lr,
    UnitType.minibatch)
  learner = C.sgd(nnet.parameters, lr_per_batch)
  trainer = C.Trainer(nnet, (ce, pe), [learner])
  max_iter = 5000  # 5000 maximum training iterations
  batch_size = 5   # mini-batch size  5
  progress_freq = 1000  # print error every n minibatches
  reader_train = create_reader(train_file, True, input_dim,
    output_dim)
  my_input_map = {
    input_Var : reader_train.streams.features,
    label_Var : reader_train.streams.labels
  }
  pp = ProgressPrinter(progress_freq)
  print("Starting training \n")
  for i in range(0, max_iter):
    currBatch = reader_train.next_minibatch(batch_size,
      input_map = my_input_map)
    trainer.train_minibatch(currBatch)
    pp.update_with_trainer(trainer)
  print("\nTraining complete")
  # ----------------------------------
  print("\nEvaluating test data \n")
  reader_test = create_reader(test_file, False, input_dim,
    output_dim)
  numTestItems = 30
  allTest = reader_test.next_minibatch(numTestItems,
    input_map = my_input_map)
  test_error = trainer.test_minibatch(allTest)
  print("Classification error on the 30 test items = %f"
    % test_error)
  # ----------------------------------
  # make a prediction for an unknown flower
  # first train versicolor = 7.0,3.2,4.7,1.4,0,1,0
  unknown = np.array([[6.9, 3.1, 4.6, 1.3]],
    dtype=np.float32)
  print("\nPredicting Iris species for input features: ")
  my_print(unknown[0], 1)  # 1 decimal
  predicted = nnet.eval( {input_Var: unknown} )
  print("Prediction is: ")
  my_print(predicted[0], 3)  # 3 decimals
  # ---------------------------------
  print("\nTrained model input-to-hidden weights: \n")
  print(hLayer.hidLayer.W.value)
  print("\nTrained model hidden node biases: \n")
  print(hLayer.hidLayer.b.value)
  print("\nTrained model hidden-to-output weights: \n")
  print(oLayer.outLayer.W.value)
  print("\nTrained model output node biases: \n")
  print(oLayer.outLayer.b.value)
  save_weights("weights.txt", hLayer.hidLayer.W.value,
    hLayer.hidLayer.b.value, oLayer.outLayer.W.value,
    oLayer.outLayer.b.value)
  return 0  # success
def main():
  print("\nBegin Iris demo (CNTK 2.0) \n")
  np.random.seed(0)
  do_demo()  # all the work is done in do_demo()
if __name__ == "__main__":
  main()
# end script

# def create_reader(path, is_training, input_dim, output_dim):
  return MinibatchSource(CTFDeserializer(path, StreamDefs(
    features = StreamDef(field='attribs', shape=input_dim,
      is_sparse=False),
    labels = StreamDef(field='species', shape=output_dim,
      is_sparse=False)
  )), randomize = is_training,
    max_sweeps = INFINITELY_REPEAT if is_training else 1)

